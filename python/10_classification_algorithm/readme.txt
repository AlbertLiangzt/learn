分类算法——朴素贝叶斯 (NaiveBeyesian Classification NB)
原理
	朴素贝叶斯分类
	1.将80%的文章作为训练集，将20%的文章作为训练集
		1.1 将文章按照文件名分类
		1.2 将文章切割成词组
		1.3 将文章中的词记录在词典中，形成“词-id”一一对应的形式
		1.4 将原文章以id的形式输出
		OUT	->	训练集	文章类型 id_1 id_2 id_3 ... 文件名
						文章类型 id_4 id_5 id_6 ... 文件名
						...
				测试集	文章类型 id_1 id_2 id_3 ... 文件名
                		文章类型 id_4 id_5 id_6 ... 文件名
                        ...
	
	2.利用训练集，得到一个模型
		2.1 获取文章文本特征
			2.1.1 将未出现的词语保存在词典wordDic中
			2.1.2 统计词语出现的次数，存在词典classDic中
			2.1.3 求出最大似然——特征x和类别y，在训练中同时出现的次数
		2.2 求先验概率
			2.2.1 求出文章的先验概率
			2.2.2 求出该类文章中每个词语的先验概率
		2.3 保存模型
		
		OUT	->	文章类型	文章先验概率	词语默认概率	文章类型	文章先验概率	词语默认概率...
				文章类型(未输出,每行都为一个文章类型)	词语id	最大似然估计
				文章类型(未输出,每行都为一个文章类型)	词语id	最大似然估计
				...


	3.利用测试集，评估模型效果
		3.1 读取模型，读出文章类型、文章先验概率、词语默认概率、词语id、词语最大似然估计
		3.2 预测
			3.2.1 读取测试数据
			3.2.3 获取每篇文章的类型、词频
			3.2.3 计算每篇文章的所有词语在各类文章的概率
					计算公式如图nb.png
			3.2.3 选出概率最大的，即为预测类型

		IN	->	文章类型(未输出)	词语id	最大似然估计
		OUT	->	文章类型	预测类型
				文章类型	预测类型
				...

实现步骤
	python DataConvert.py data/ nb_data

	python GenerateModel.py nb_data.train model

	python EvaluateModel.py nb_data.test model result



