# å›å½’ç®—æ³• LRç®—æ³•

äºŒåˆ†ç±»(Logistic Regression é€»è¾‘æ–¯è°›å›å½’ ç®€ç§°LR)ï¼šmodel -> 0/1

å¤šåˆ†ç±»(Softmax)ï¼šmodel -> 0/1/2...

## ä¸€ã€Sigmoidå‡½æ•°â€”â€”é€»è¾‘å›å½’çš„å®ç°

### 1.

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20200628180453581.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYmVydExpYW5nenQ=,size_16,color_FFFFFF,t_70)

### 2.ç”¨sigmoidåŸå› ï¼š

- ç®€å•æ¥è®²ï¼Œå¯ä»¥å°†(-âˆ, +âˆ)çš„è¾“å…¥å˜é‡æ˜ å°„åˆ°(0,1)ï¼Œä½œä¸ºåéªŒæ¦‚ç‡
- åœ¨æŸä¸ªä¸´ç•Œç‚¹å·¦å³ä¸¤ç«¯å˜åŒ–è¾ƒå¤§ï¼Œæ¯”è¾ƒå®¹æ˜“è¿›è¡Œåˆ†ç±»

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20200629104201740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FsYmVydExpYW5nenQ=,size_16,color_FFFFFF,t_70)


## äºŒã€åŸºæœ¬å…¬å¼æ¨å¯¼
### 1.å¯¹sigmoidæ±‚wåå¯¼ï¼š
$\eta(t)=\frac{1}{1+e^{-t}}$ è½¬æ¢ä¸º $\eta(wx)=\frac{1}{1+e^{-wx}}$

åå¯¼ä¸º$\frac{\partial(\eta)}{\partial(w)}$ $=\frac{(-1)}{(1+e^{-wx})^{2}} *(-x)*(e^{-wx}) $

$=\frac{1}{1+e^{-wx}} * \frac{e^{-wx}}{1+e^{-wx}} * x$

$=\frac{1}{1+e^{-wx}} * \frac{1+e^{-wx}-1}{1+e^{-wx}} * x$

$=\frac{1}{1+e^{-wx}} * (1 - \frac{1}{1+e^{-wx}}) * x$

$=\eta * (1-\eta) * x$

### 2.å¯¹æŸå¤±å‡½æ•°$L(w)$æ±‚å¯¼ï¼ˆæ¢¯åº¦ï¼‰ï¼š

#### 2.1ç±»åˆ«æ¦‚ç‡
$p(y_{i}=1|x)=\eta$
$p(y_{i}=0|x)=1-\eta$

#### 2.2ä¼¼ç„¶å‡½æ•°
$L(w)=\prod\limits_{i}p(y_{i})$
$=\prod\limits_{i}(I(y_{i}=1)p(y_{i}=1|x_{i},w)) * I(y_{i}=0)p((y_{i}=0)|x_{i},w))$
$=\prod\limits_{i}y_{i}\eta * (1-y_{i})(1-\eta)$

#### 2.3è´Ÿå¯¹æ•°ä¼¼ç„¶

$log(L(w))=-log(\prod\limits_{i}y_{i}\eta * (1-y_{i})(1-\eta))$
$log(L(w))=-\sum\limits_{i}(y_{i}log(\eta)+(1-y_{i})log((1-\eta))$
 
ä¹Ÿå†™ä½œ

$L(w)=-\sum\limits_{i}(I(y_{i}=1)log(p(y_{i}=1|x_{i},w))) + I(y_{i}=0)log(p((y_{i}=0)|x_{i},w)))$
$=-\sum\limits_{i}(I(y_{i}=1)log(\eta(wx_{i})) + I(y_{i}=0)log(1-\eta(wx_{i})))$

#### 2.4æ‰€ä»¥è´Ÿå¯¹æ•°ä¼¼ç„¶æ±‚åå¯¼

$$\delta(L(w))=-\sum(\frac{y_{i}}{\eta}\eta(1-\eta)x_{i} - \frac{1-y_{i}}{1-\eta}\eta(1-\eta)x_{i})$$
$$=-\sum(y_{i}(1-\eta)x_{i}+(1-y_{i})\eta x_{i})$$
$$=-\sum(y_{i}x_{i}-y_{i}\eta  x_{i}-\eta x_{i}+y_{i}\eta x_{i})$$
$$=-\sum(y_{i}-\eta) x_{i}$$

#### <font color=red>æ‰€ä»¥æ¢¯åº¦ä¸º:$\nabla(L(w))=-\sum(y_{i}-\eta) x_{i}$</font>


## ä¸‰ã€ä¸¾ä¾‹ï¼šåˆ°è¾¾è°·åº•çš„æœ€ä½³è·¯çº¿

### æ¢¯åº¦

æ¢¯åº¦æ–¹å‘â€”â€”è®©f(x,y)å‡½æ•°å¿«é€Ÿå˜å¤§çš„æ–¹å‘
åæ¢¯åº¦æ–¹å‘â€”â€”è®©f(x,y)å‡½æ•°å¿«é€Ÿå˜å°çš„æ–¹å‘

### æ–¹æ³•ï¼šæ¢¯åº¦ä¸‹é™æ³•â€”â€”æœ€å°åŒ–F(w)
- 1.è®¾ç½®åˆå§‹wï¼Œè®¡ç®—å‡ºF(w)
- 2.è®¡ç®—æ¢¯åº¦$\nabla$ï¼šä¸‹é™æ–¹å‘dir=(-$\nabla$F(w))
- 3.å°è¯•æ¢¯åº¦æ›´æ–°ï¼š$w^{new} = w + æ­¥é•¿*dir$
    å¾—åˆ°ä¸‹é™åçš„$w^{new}$å’ŒF($w^{new}$)
- 4.å¦‚æœF($w^{new}$)-F(w)è¾ƒå°ï¼šè¯´æ˜åŸºæœ¬å¤„äºåº•éƒ¨ï¼Œæ¨¡å‹ç¨³å®šï¼Œå¯ä»¥åœæ­¢
    å¦åˆ™w=$w^{new}$, F($w^{new}$)=F(w)

### å®ç°

è¯¯å·®=çœŸå®å€¼-é¢„æµ‹å€¼=(yi - $\eta(wx_{i})$)
errors = target - prediction
prediction = sigmoid(wx)=ğœ‚(wx)
wx = weight * x + b
$w_{1}$ï¼šéšæœºåˆå§‹åŒ– => f(x)ï¼šé¢„æµ‹å€¼